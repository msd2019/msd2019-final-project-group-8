{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSD 2019 Final Project\n",
    "\n",
    "## A replication and extension of \"Automated Hate Speech Detection and the Problem of Offensive Language\" by Thomas Davidson, Dana Warmsley, Michael Macy, Ingmar Weber4 Published in ICWSM 2017.\n",
    "\n",
    "### Ketakee Nimavat (kkn2112), Chandana priya (cg3111), Ankit Peshin (ap3772) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Motivation\n",
    "\n",
    "The main focus of this paper was  the differentiation between hate speech and offensive speech. Drawing from the definitions of the paper, hate speech is  language that is used to expresses hatred towards a targeted group or is intended to be derogatory, to humiliate, or to insult the members of the group. The targets usually are a minority group or people with disadvantage. In extreme cases, this hate speech can sometimes insinuate violence.  On the other hand, offensive speech is defined as  the language of sexisim and obscene comments made by one person to another. \n",
    "\n",
    "Because of its seriousness, many countries like France, UK, Canada pose legal implications/charges to those found guilty of using hate speech. These laws usually extends to TV, media and the internet. Given this scenario, it becomes necessary to distinguish between the two highly similar languages. The paper mainly concentrates on this specific issue. The ground truth for this analysis is collected via crowdsourcing where each tweet/text is classified as hate speech, offensive or neither. The paper also discusses about when this distinction is not feasible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replication & Implementation Overview\n",
    "\n",
    "To reproduce the results from the paper, we used the same dataset provided by the authors, containing about 25k sample tweets and their corresponding labels assigned via crowdsourcing. Each tweet had mentions, retweets and/or hashtags. To have a count on the number of mentions and urls and to identify if it was a retweet, we replaces any url sequence with ‘URLHERE’, @_name__ with ‘MENTIONHERE’ and check if there was a ‘rt’ (retweet) to indicate if it was a retweet. \n",
    "\n",
    "We later cleaned the tweets to remove special characters and tokenize the words. We also removed stopwords from the tweets using the NLTK library. Once we have the tweets tokenized to words, we used the stemming technique to identify tokens by their root words. The NLP toolkit provides built in packages for stemming words with many variants. We’ve used PorterStemmer in the implementation.  Furthermore, the Part-of-Speech (POS) tags for  unigrams, bigrams, and trigrams are computed. To capture the quality of each tweet we use modified Flesch-Kincaid scores and also calculated the sentiment score associated with each tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps for replication\n",
    "\n",
    "\n",
    "## Data \n",
    "The data corpus we used for replicating the results from \"Automated Hate Speech Detection and the Problem of Offensive Language\" is the original dataset, provided by the author. This data has been generated by crowdsourcing various tweets with their corresponding labels. This forms the ground truth for our analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1ki86DaRVLa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hlMuOnSbu087"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "aa8OgM7Ou2aD",
    "outputId": "5173b29e-82b7-4996-c4b3-8a0eb268ecca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.6/dist-packages (3.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hegsHcg9u392"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "import nltk\n",
    "import gensim\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "from gensim import corpora\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8wfqIlUSD5Wz"
   },
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uVNqjc-ku6gb"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/data/labeled_data.csv\")[[\"tweet\",\"class\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "kQCg7uAXu9-m",
    "outputId": "40037884-c3cb-4da7-dd9f-3ba6c184340c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  class\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...      2\n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...      1\n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...      1\n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...      1\n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SD0gT7haEvE8"
   },
   "source": [
    "Here we take equal data from all classes, one class has a little bit less data but that is a minor imbalance that can be tolerated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WIvrCqm7vBSy",
    "outputId": "8483c1ae-105d-4d63-c844-b0c5f7b39232"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3430"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train[df_train['class']==0][\"tweet\"]\n",
    "X__train = df_train[df_train['class']==1][\"tweet\"][:1000]\n",
    "X_train = X_train.append(X__train)\n",
    "X__train = df_train[df_train['class']==2][\"tweet\"][:1000]\n",
    "X_train = X_train.append(X__train)\n",
    "y_train = df_train[df_train['class']==0][\"class\"]\n",
    "y_train = y_train.append(df_train[df_train['class']==1][\"class\"][:1000])\n",
    "y_train = y_train.append(df_train[df_train['class']==2][\"class\"][:1000])\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4pYhf1IKvMKl",
    "outputId": "8a1aa9f1-8bfb-4476-8783-fc3f9d166145"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3430"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_7CO-FUPvbwV"
   },
   "source": [
    "## Feature Enginerring \n",
    "Since we are dealing with unstructured data, we used preprocessing, stemming, vectorization, POS tag and sentiment scores to consider right words (tokens) to the features set along with some summary statistics like number of number of words, characters, number of times a URL was sited, number of times a tweet was retweeted, number of mentions etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6YM7zSGv44u"
   },
   "source": [
    "1. Lowercase\n",
    "2. Stem\n",
    "3. bigram, unigram, trigram features, weighted by its tfidf\n",
    "4. POS tag\n",
    "5. FK Grade level\n",
    "6. FK reading ease score\n",
    "7. sentiment scores\n",
    "\n",
    "8. binary indicators for: hashtags, mentions, retweets, urls\n",
    "9. count indicatiors for :hashtags, mentions, retweets, urls\n",
    "10. number of characters\n",
    "11. numbers of words\n",
    "12. number of syllables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "H_0b2hH3Q2oZ",
    "outputId": "27f1dfdb-07b9-422e-af7c-a270a1741a45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1P0chojPvYqx"
   },
   "outputs": [],
   "source": [
    "stopwords=stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "other_exclusions = [\"#ff\", \"ff\", \"rt\",\"RT\"]\n",
    "stopwords.extend(other_exclusions)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess(text_string):\n",
    "    \n",
    "    #Lowercase string\n",
    "    text_string=text_string.lower()\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "    parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
    "    \n",
    "    #Stem it\n",
    "    tweet = \" \".join(re.split(\"[^a-zA-Z]*\", parsed_text)).strip()\n",
    "    tokens = [stemmer.stem(t) for t in tweet.split()]\n",
    "    return tokens\n",
    "  \n",
    "  \n",
    "def pos_tag_seq(tokens):\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    tag_list = [x[1] for x in tags]\n",
    "    tag_str = \" \".join(tag_list)\n",
    "    return tag_str\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BIwfyzsh9dEO"
   },
   "outputs": [],
   "source": [
    "def join_sent(l):\n",
    "  return \" \".join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5jKGjGcaTYI3"
   },
   "outputs": [],
   "source": [
    "df_train=pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hVkColl0Ti5-"
   },
   "outputs": [],
   "source": [
    "df_train.columns=[\"tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "XBtZY8XbTqXU",
    "outputId": "82820288-339f-455c-d17b-468fd13989fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>\"@Blackman38Tide: @WhaleLookyHere @HowdyDowdy1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>\"@CB_Baby24: @white_thunduh alsarabsss\" hes a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>\"@DevilGrimz: @VigxRArts you're fucking gay, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>\"@MarkRoundtreeJr: LMFAOOOO I HATE BLACK PEOPL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>\"@NoChillPaz: \"At least I'm not a nigger\" http...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet\n",
       "85   \"@Blackman38Tide: @WhaleLookyHere @HowdyDowdy1...\n",
       "89   \"@CB_Baby24: @white_thunduh alsarabsss\" hes a ...\n",
       "110  \"@DevilGrimz: @VigxRArts you're fucking gay, b...\n",
       "184  \"@MarkRoundtreeJr: LMFAOOOO I HATE BLACK PEOPL...\n",
       "202  \"@NoChillPaz: \"At least I'm not a nigger\" http..."
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "mfiVVPJEQqPu",
    "outputId": "c2f77526-de4e-413d-ba87-248cd9cd9f79"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "s_train=df_train['tweet'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TUI-yrgjAVXb"
   },
   "outputs": [],
   "source": [
    "s_tr=s_train.apply(join_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "ontO83dNTWqp",
    "outputId": "b46354b2-8778-48ed-cfeb-73ced7e0f6e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "t_tr=s_train.apply(pos_tag_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fU316-WsTNwT"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    preprocessor=None,\n",
    "    lowercase=False,\n",
    "    ngram_range=(1, 3),\n",
    "    use_idf=True,\n",
    "    smooth_idf=False,\n",
    "    norm=None,\n",
    "    stop_words=stopwords,\n",
    "    decode_error='replace',\n",
    "    max_features=10000,\n",
    "    min_df=5,\n",
    "    max_df=0.75\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-UdkR9MG-_Vc"
   },
   "outputs": [],
   "source": [
    "pos_vectorizer = TfidfVectorizer(\n",
    "    tokenizer=None,\n",
    "    lowercase=False,\n",
    "    preprocessor=None,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words=None,\n",
    "    use_idf=False,\n",
    "    smooth_idf=False,\n",
    "    norm=None,\n",
    "    decode_error='replace',\n",
    "    max_features=5000,\n",
    "    min_df=5,\n",
    "    max_df=0.75,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GjIbAPqGZ6sR"
   },
   "outputs": [],
   "source": [
    "tfidf_tr = vectorizer.fit_transform(s_tr).toarray()\n",
    "\n",
    "vocab = {v:i for i, v in enumerate(vectorizer.get_feature_names())}\n",
    "idf_vals = vectorizer.idf_\n",
    "idf_dict = {i:idf_vals[i] for i in vocab.values()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ElfB-H5A4eh"
   },
   "outputs": [],
   "source": [
    "pos_tr = pos_vectorizer.fit_transform(t_tr).toarray()\n",
    "\n",
    "pos_vocab = {v:i for i, v in enumerate(pos_vectorizer.get_feature_names())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kTxPJAbQBBwj"
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as VS\n",
    "sentiment_analyzer = VS()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FH9l_ymsBVsi"
   },
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "  sentiment = sentiment_analyzer.polarity_scores(text)\n",
    "  return sentiment\n",
    "\n",
    "#   return sentiment[\"neg\"], sentiment[\"pos\"], sentiment[\"neu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkes6ZUlBdun"
   },
   "outputs": [],
   "source": [
    "df_train[\"sent\"]=df_train[\"tweet\"].apply(get_sentiment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "CGdJcLFjFdi2",
    "outputId": "3913a153-6a4f-4f94-a4c9-b687a6ee70ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>\"@Blackman38Tide: @WhaleLookyHere @HowdyDowdy1...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>\"@CB_Baby24: @white_thunduh alsarabsss\" hes a ...</td>\n",
       "      <td>{'neg': 0.187, 'neu': 0.813, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>\"@DevilGrimz: @VigxRArts you're fucking gay, b...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>\"@MarkRoundtreeJr: LMFAOOOO I HATE BLACK PEOPL...</td>\n",
       "      <td>{'neg': 0.254, 'neu': 0.746, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>\"@NoChillPaz: \"At least I'm not a nigger\" http...</td>\n",
       "      <td>{'neg': 0.232, 'neu': 0.488, 'pos': 0.28, 'com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet  \\\n",
       "85   \"@Blackman38Tide: @WhaleLookyHere @HowdyDowdy1...   \n",
       "89   \"@CB_Baby24: @white_thunduh alsarabsss\" hes a ...   \n",
       "110  \"@DevilGrimz: @VigxRArts you're fucking gay, b...   \n",
       "184  \"@MarkRoundtreeJr: LMFAOOOO I HATE BLACK PEOPL...   \n",
       "202  \"@NoChillPaz: \"At least I'm not a nigger\" http...   \n",
       "\n",
       "                                                  sent  \n",
       "85   {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "89   {'neg': 0.187, 'neu': 0.813, 'pos': 0.0, 'comp...  \n",
       "110  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "184  {'neg': 0.254, 'neu': 0.746, 'pos': 0.0, 'comp...  \n",
       "202  {'neg': 0.232, 'neu': 0.488, 'pos': 0.28, 'com...  "
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P6OWYD3IGfEb"
   },
   "outputs": [],
   "source": [
    "foo_tr = lambda x: pd.Series([x[\"pos\"],x[\"neg\"],x[\"neu\"]])\n",
    "rev_tr = df_train['sent'].apply(foo_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zK52xDCsHGo8"
   },
   "outputs": [],
   "source": [
    "rev_tr.columns=[\"pos\",\"neg\",\"neu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "COsKHAimHIxF",
    "outputId": "16f84791-7e22-4ade-9f14-7d41bedb8142"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pos    neg    neu\n",
       "85   0.00  0.000  1.000\n",
       "89   0.00  0.187  0.813\n",
       "110  0.00  0.000  1.000\n",
       "184  0.00  0.254  0.746\n",
       "202  0.28  0.232  0.488"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cYafNXGvIIVt"
   },
   "source": [
    "### Binary count for URL https mentions etc \n",
    "we replace each URL expression with \"URLHERE\" and each '@....' with a  \"MENTIONHERE\" so that we can later keep track of the number of occurences of these terms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ck29bhNNIMwy"
   },
   "outputs": [],
   "source": [
    "def return_cont(parsed_text):\n",
    "  return(parsed_text.count('urlher'),parsed_text.count('mentionher'),parsed_text.count('hashtagher'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWSXyarzIb_P"
   },
   "outputs": [],
   "source": [
    "df_train[\"counts\"]=s_tr.apply(return_cont) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "YLa-ctKSJOYT",
    "outputId": "928a5bb9-17b9-43e3-8b52-2cc8688182ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85     (0, 3, 0)\n",
       "89     (0, 2, 0)\n",
       "110    (1, 2, 1)\n",
       "184    (1, 1, 0)\n",
       "202    (1, 1, 0)\n",
       "Name: counts, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"counts\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ak7gCgImJQlS"
   },
   "outputs": [],
   "source": [
    "foo = lambda x: pd.Series([x[0],x[1],x[2]])\n",
    "mention_counts_tr = df_train['counts'].apply(foo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "f_cIuZXbJuIA",
    "outputId": "976a1b0c-81fe-47b0-b2cc-d0b65911e129"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2\n",
       "85   0  3  0\n",
       "89   0  2  0\n",
       "110  1  2  1\n",
       "184  1  1  0\n",
       "202  1  1  0"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mention_counts_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mSIJb-4oJx0-"
   },
   "source": [
    "### FKRA and Flesch and number of syllables etc\n",
    "\n",
    "FKRA is our go to solution for English syntax parsing, and some additional features like number of syllables, characters,words, etc. should give greater insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "yxCy5UqgObNJ",
    "outputId": "7688cf76-262e-46bf-f9ba-53d065f4f169"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textstat in /usr/local/lib/python3.6/dist-packages (0.5.6)\n",
      "Requirement already satisfied: pyphen in /usr/local/lib/python3.6/dist-packages (from textstat) (0.9.5)\n",
      "Requirement already satisfied: repoze.lru in /usr/local/lib/python3.6/dist-packages (from textstat) (0.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install textstat\n",
    "from textstat.textstat import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H1LY6enHJwdr"
   },
   "outputs": [],
   "source": [
    "def get_other_features(text):\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text)\n",
    "    parsed_text = re.sub(giant_url_regex, '', parsed_text)\n",
    "    words = re.sub(mention_regex, '', parsed_text)\n",
    "    \n",
    "    syllables = textstat.syllable_count(words)\n",
    "    num_chars = sum(len(w) for w in words)\n",
    "    num_chars_total = len(text)\n",
    "    num_terms = len(text.split())\n",
    "    num_words = len(words.split())\n",
    "    avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
    "    num_unique_terms = len(set(words.split()))\n",
    "    \n",
    "    ###Modified FK grade, where avg words per sentence is just num words/1\n",
    "    FKRA = round(float(0.39 * float(num_words)/1.0) + float(11.8 * avg_syl) - 15.59,1)\n",
    "    ##Modified FRE score, where sentence fixed to 1\n",
    "    FRE = round(206.835 - 1.015*(float(num_words)/1.0) - (84.6*float(avg_syl)),2)\n",
    "    \n",
    "    features = [FKRA, FRE,syllables, avg_syl, num_chars, num_terms, num_words,\n",
    "                num_unique_terms]\n",
    "    return features\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lq_5yJArONvX"
   },
   "outputs": [],
   "source": [
    "other_feats_tr=df_train[\"tweet\"].apply(get_other_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "2jUZJA9-OSgq",
    "outputId": "3d4217c5-ad11-490c-f073-7236b44dc72c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85         [9.2, 34.62, 6, 1.9997, 18, 5, 3, 3]\n",
       "89        [6.8, 67.76, 18, 1.5, 59, 13, 12, 10]\n",
       "110    [9.1, 49.55, 19, 1.7272, 76, 13, 11, 11]\n",
       "184    [5.2, 84.46, 19, 1.2666, 78, 15, 15, 15]\n",
       "202        [2.3, 94.3, 11, 1.2222, 38, 9, 9, 9]\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_feats_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H-gNv_dIO1d2"
   },
   "outputs": [],
   "source": [
    "other_features_names = [\"FKRA\", \"FRE\",\"num_syllables\", \"avg_syl_per_word\", \"num_chars\",\"num_terms\", \"num_words\", \"num_unique_words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G3VYN6oeWU6H"
   },
   "outputs": [],
   "source": [
    "foo = lambda x: pd.Series(elem for elem in x)\n",
    "of_counts_tr = other_feats_tr.apply(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "Rz-96sBOWlgK",
    "outputId": "b7f1e48e-2ca6-46dc-be01-4e096036a359"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>9.2</td>\n",
       "      <td>34.62</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.9997</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>6.8</td>\n",
       "      <td>67.76</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>59.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>9.1</td>\n",
       "      <td>49.55</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.7272</td>\n",
       "      <td>76.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>5.2</td>\n",
       "      <td>84.46</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.2666</td>\n",
       "      <td>78.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2.3</td>\n",
       "      <td>94.30</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.2222</td>\n",
       "      <td>38.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1     2       3     4     5     6     7\n",
       "85   9.2  34.62   6.0  1.9997  18.0   5.0   3.0   3.0\n",
       "89   6.8  67.76  18.0  1.5000  59.0  13.0  12.0  10.0\n",
       "110  9.1  49.55  19.0  1.7272  76.0  13.0  11.0  11.0\n",
       "184  5.2  84.46  19.0  1.2666  78.0  15.0  15.0  15.0\n",
       "202  2.3  94.30  11.0  1.2222  38.0   9.0   9.0   9.0"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "of_counts_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8N_fFXxtPzIu"
   },
   "outputs": [],
   "source": [
    "of_counts_tr.columns=other_features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "yp8nF10nWDxv",
    "outputId": "ff4e9217-7960-4ec4-87be-e0c776dd78ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FKRA</th>\n",
       "      <th>FRE</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>avg_syl_per_word</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_terms</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>9.2</td>\n",
       "      <td>34.62</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.9997</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>6.8</td>\n",
       "      <td>67.76</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>59.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>9.1</td>\n",
       "      <td>49.55</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.7272</td>\n",
       "      <td>76.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>5.2</td>\n",
       "      <td>84.46</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.2666</td>\n",
       "      <td>78.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2.3</td>\n",
       "      <td>94.30</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.2222</td>\n",
       "      <td>38.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FKRA    FRE  num_syllables  avg_syl_per_word  num_chars  num_terms  \\\n",
       "85    9.2  34.62            6.0            1.9997       18.0        5.0   \n",
       "89    6.8  67.76           18.0            1.5000       59.0       13.0   \n",
       "110   9.1  49.55           19.0            1.7272       76.0       13.0   \n",
       "184   5.2  84.46           19.0            1.2666       78.0       15.0   \n",
       "202   2.3  94.30           11.0            1.2222       38.0        9.0   \n",
       "\n",
       "     num_words  num_unique_words  \n",
       "85         3.0               3.0  \n",
       "89        12.0              10.0  \n",
       "110       11.0              11.0  \n",
       "184       15.0              15.0  \n",
       "202        9.0               9.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "of_counts_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1949
    },
    "colab_type": "code",
    "id": "OLdSjcJ7P9SH",
    "outputId": "85b0ff37-0f3b-447a-8ea2-fe34370f6ad5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>\"@Blackman38Tide: @WhaleLookyHere @HowdyDowdy1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>\"@CB_Baby24: @white_thunduh alsarabsss\" hes a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>\"@DevilGrimz: @VigxRArts you're fucking gay, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>\"@MarkRoundtreeJr: LMFAOOOO I HATE BLACK PEOPL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>\"@NoChillPaz: \"At least I'm not a nigger\" http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>\"@NotoriousBM95: @_WhitePonyJr_ Ariza is a sna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>\"@RTNBA: Drakes new shoes that will be release...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>\"@TheoMaxximus: #GerrysHalloweenParty http://t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>\"@ashlingwilde: @ItsNotAdam is bored supposed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>\"@bigbootybishopp: @white_thunduh lassen cc , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>\"@jayswaggkillah: Jackies a retard #blondeprob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>\"@jgabsss: Stacey Dash won &amp;#128166; http://t....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>\"Don't worry about the nigga you see, worry ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>\"Hey go look at that video of the man that fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>\"Let's kill cracker babies!\". WTF did I just h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>\"My grandma used to call me a porch monkey all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>\"Nah its You @NoMeek_JustMilz: &amp;#128514;&amp;#1285...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>\"Our people\". Now is the time for the Aryan ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>\"These sour apple bitter bitches, I'm not fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>\"We hate niggers, we hate faggots and we hate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>\"We're out here, and we're queer!\"\\n\" 2, 4, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>\"Who the fuck you callin jiggaboo, nigga?!\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>\"Why people think gay marriage is okay is beyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>\"You ain't gunna do shit spear chucker\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>\"You ol trout mouth ass bitch\" \\nDEEEEAAAADD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>\"ayo i even kill handicapped and crippled bitc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>\"fuck you you pussy ass hater go suck a dick a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>\"on my way to fuck your bitch in the name of T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>\"poor whitey\" http://t.co/3UkKeyznz8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>#AZmonsoon lot of rain, too bad it wasn't enou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5743</th>\n",
       "      <td>@clangloisss hmu negro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5744</th>\n",
       "      <td>@claraoswined cute, but I love her yellow rain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5746</th>\n",
       "      <td>@cleggzta Ho ho ho.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5751</th>\n",
       "      <td>@cnnbrk let me guess they have yellow cake too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5758</th>\n",
       "      <td>@contrarian11 @YouTube yeah. great song. just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5768</th>\n",
       "      <td>@craigcalcaterra Hes behind the plate for the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5779</th>\n",
       "      <td>@cryancarfield haven't you ever heard the stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5783</th>\n",
       "      <td>@cullenbunn Maybe Baylee Ann, Tater Pud, Nurse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5784</th>\n",
       "      <td>@cumkwats thank you based pee slit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>@cxslug I never did those games, but I was obs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>@d6_9b idk... It's trash though!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>@dabbba @Pinchehonkey Far as I can tell coon t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>@daggerbyte @MichaelSmartGuy @spacej_me @pizza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5794</th>\n",
       "      <td>@daishialopez how could you say such a thing w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5802</th>\n",
       "      <td>@danifreshh some weird local ghetto school haha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5806</th>\n",
       "      <td>@danram70 pussy. It's science. Donaire via Rac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5812</th>\n",
       "      <td>@darealwalt_jr he see the jig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5813</th>\n",
       "      <td>@darrenburton_ and take the trash out and sepa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5815</th>\n",
       "      <td>@datachick Humanity really needs to get past t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5825</th>\n",
       "      <td>@dchestnut26 don't shake your head at me. I ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5845</th>\n",
       "      <td>@derek_gatewood it's not ghetto you fool.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5847</th>\n",
       "      <td>@desamador you gotta be like me n the twins, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5850</th>\n",
       "      <td>@dgardner @YoniFreedhoff Sounds like the hyste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5855</th>\n",
       "      <td>@discordianslip I hope my fuzzy head doesnt ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5857</th>\n",
       "      <td>@dish \\nWas just wondering if yo espect to add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5869</th>\n",
       "      <td>@dminion25 it's kinda screwed up that they wer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5871</th>\n",
       "      <td>@dolphrudager Nope, never taken neighbors actu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>@dolphrudager Only one current Yankee sells! O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5885</th>\n",
       "      <td>@dreadywhiteboy @JwanUrebay then the kid he so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5893</th>\n",
       "      <td>@dustincmc @KevinKillsThngs ghetto=black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3430 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet\n",
       "85    \"@Blackman38Tide: @WhaleLookyHere @HowdyDowdy1...\n",
       "89    \"@CB_Baby24: @white_thunduh alsarabsss\" hes a ...\n",
       "110   \"@DevilGrimz: @VigxRArts you're fucking gay, b...\n",
       "184   \"@MarkRoundtreeJr: LMFAOOOO I HATE BLACK PEOPL...\n",
       "202   \"@NoChillPaz: \"At least I'm not a nigger\" http...\n",
       "204   \"@NotoriousBM95: @_WhitePonyJr_ Ariza is a sna...\n",
       "219   \"@RTNBA: Drakes new shoes that will be release...\n",
       "260   \"@TheoMaxximus: #GerrysHalloweenParty http://t...\n",
       "312   \"@ashlingwilde: @ItsNotAdam is bored supposed ...\n",
       "315   \"@bigbootybishopp: @white_thunduh lassen cc , ...\n",
       "349   \"@jayswaggkillah: Jackies a retard #blondeprob...\n",
       "352   \"@jgabsss: Stacey Dash won &#128166; http://t....\n",
       "437   \"Don't worry about the nigga you see, worry ab...\n",
       "459   \"Hey go look at that video of the man that fou...\n",
       "519   \"Let's kill cracker babies!\". WTF did I just h...\n",
       "526   \"My grandma used to call me a porch monkey all...\n",
       "531   \"Nah its You @NoMeek_JustMilz: &#128514;&#1285...\n",
       "540   \"Our people\". Now is the time for the Aryan ra...\n",
       "565   \"These sour apple bitter bitches, I'm not fuck...\n",
       "582   \"We hate niggers, we hate faggots and we hate ...\n",
       "583   \"We're out here, and we're queer!\"\\n\" 2, 4, 6,...\n",
       "587         \"Who the fuck you callin jiggaboo, nigga?!\"\n",
       "588   \"Why people think gay marriage is okay is beyo...\n",
       "603             \"You ain't gunna do shit spear chucker\"\n",
       "614        \"You ol trout mouth ass bitch\" \\nDEEEEAAAADD\n",
       "625   \"ayo i even kill handicapped and crippled bitc...\n",
       "635   \"fuck you you pussy ass hater go suck a dick a...\n",
       "646   \"on my way to fuck your bitch in the name of T...\n",
       "647                \"poor whitey\" http://t.co/3UkKeyznz8\n",
       "663   #AZmonsoon lot of rain, too bad it wasn't enou...\n",
       "...                                                 ...\n",
       "5743                             @clangloisss hmu negro\n",
       "5744  @claraoswined cute, but I love her yellow rain...\n",
       "5746                                @cleggzta Ho ho ho.\n",
       "5751  @cnnbrk let me guess they have yellow cake too...\n",
       "5758  @contrarian11 @YouTube yeah. great song. just ...\n",
       "5768  @craigcalcaterra Hes behind the plate for the ...\n",
       "5779  @cryancarfield haven't you ever heard the stor...\n",
       "5783  @cullenbunn Maybe Baylee Ann, Tater Pud, Nurse...\n",
       "5784                 @cumkwats thank you based pee slit\n",
       "5788  @cxslug I never did those games, but I was obs...\n",
       "5789                   @d6_9b idk... It's trash though!\n",
       "5790  @dabbba @Pinchehonkey Far as I can tell coon t...\n",
       "5792  @daggerbyte @MichaelSmartGuy @spacej_me @pizza...\n",
       "5794  @daishialopez how could you say such a thing w...\n",
       "5802    @danifreshh some weird local ghetto school haha\n",
       "5806  @danram70 pussy. It's science. Donaire via Rac...\n",
       "5812                      @darealwalt_jr he see the jig\n",
       "5813  @darrenburton_ and take the trash out and sepa...\n",
       "5815  @datachick Humanity really needs to get past t...\n",
       "5825  @dchestnut26 don't shake your head at me. I ju...\n",
       "5845          @derek_gatewood it's not ghetto you fool.\n",
       "5847  @desamador you gotta be like me n the twins, j...\n",
       "5850  @dgardner @YoniFreedhoff Sounds like the hyste...\n",
       "5855  @discordianslip I hope my fuzzy head doesnt ti...\n",
       "5857  @dish \\nWas just wondering if yo espect to add...\n",
       "5869  @dminion25 it's kinda screwed up that they wer...\n",
       "5871  @dolphrudager Nope, never taken neighbors actu...\n",
       "5872  @dolphrudager Only one current Yankee sells! O...\n",
       "5885  @dreadywhiteboy @JwanUrebay then the kid he so...\n",
       "5893           @dustincmc @KevinKillsThngs ghetto=black\n",
       "\n",
       "[3430 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.drop([ \"sent\",\"counts\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "tG1DiBDIhXVR",
    "outputId": "ed74c986-7f17-4928-96bf-9654d4c71373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n",
      "3430\n"
     ]
    }
   ],
   "source": [
    "for elem in [pd.DataFrame(tfidf_tr),pd.DataFrame(pos_tr),rev_tr,mention_counts_tr, of_counts_tr]:\n",
    "  print(len(elem))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ccGVS6tvQG8F"
   },
   "outputs": [],
   "source": [
    "# x_train=np.column_stack([tfidf,pos,rev,mention_counts, other_feats])\n",
    "x_train=np.concatenate([pd.DataFrame(tfidf_tr),pd.DataFrame(pos_tr),rev_tr,mention_counts_tr, of_counts_tr],axis=1 )\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "wrsf_AxTSp4l",
    "outputId": "dae0ba8e-29b6-4afd-9ba5-51805ed2d74a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2744\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "A3HW9J25V4iJ",
    "outputId": "235af2f3-f993-4c47-ec01-7abbe9a6358e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2744\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PeBpTCExHfdD"
   },
   "source": [
    "## Model\n",
    "\n",
    "To replicate the model, we passed the parameters mentioned in the paper for the classifier to see if we can reproduce the results. The parameters are L2 regularization on a LogisticRegression model after doing dimensioin reduction via feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1112
    },
    "colab_type": "code",
    "id": "xpMlmKBtIVuH",
    "outputId": "4b13bab3-f4cb-4bdd-a05b-65f9657bf51f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   0.2s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   0.2s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   0.3s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   0.2s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import numpy as np\n",
    "pipe = Pipeline(\n",
    "        [('select', SelectFromModel(LogisticRegression(class_weight='balanced',\n",
    "                                                  penalty=\"l1\", C=0.01))),\n",
    "        ('model', LogisticRegression(class_weight='balanced',penalty='l2'))])\n",
    "param_grid = [{}]\n",
    "grid_search = GridSearchCV(pipe, \n",
    "                           param_grid,\n",
    "                           cv=StratifiedKFold(n_splits=5, \n",
    "                                              random_state=42).split(x_train, y_train), \n",
    "                           verbose=2)\n",
    "model = grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1QHkFhOJI6-r"
   },
   "outputs": [],
   "source": [
    "y_preds = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "LFlWaeDjXI4-",
    "outputId": "12f64dc5-9aaf-4d74-c6ca-cc62bee4718b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7274052478134111"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627
    },
    "colab_type": "code",
    "id": "Bw2BK3idkUOu",
    "outputId": "93da2f21-f6a2-4889-a987-7bd2346b0ee3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.23730369]),\n",
       " 'mean_score_time': array([0.00467587]),\n",
       " 'mean_test_score': array([0.72740525]),\n",
       " 'mean_train_score': array([0.73651688]),\n",
       " 'params': [{}],\n",
       " 'rank_test_score': array([1], dtype=int32),\n",
       " 'split0_test_score': array([0.72727273]),\n",
       " 'split0_train_score': array([0.7461258]),\n",
       " 'split1_test_score': array([0.72727273]),\n",
       " 'split1_train_score': array([0.73154057]),\n",
       " 'split2_test_score': array([0.70437956]),\n",
       " 'split2_train_score': array([0.73907104]),\n",
       " 'split3_test_score': array([0.75547445]),\n",
       " 'split3_train_score': array([0.73315118]),\n",
       " 'split4_test_score': array([0.72262774]),\n",
       " 'split4_train_score': array([0.73269581]),\n",
       " 'std_fit_time': array([0.02594034]),\n",
       " 'std_score_time': array([0.00180653]),\n",
       " 'std_test_score': array([0.0163644]),\n",
       " 'std_train_score': array([0.00546895])}"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AvfyEiJ-jU_-",
    "outputId": "614dc77b-8619-40bf-c1e3-afc520492724"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and Analaysis\n",
    "\n",
    "# Precison, Recall and f1-score\n",
    "By definition, we know that precison is the number of datapoints that are actually true divided over the total number of datapoints predicted true, while recall is the fraction of predicted true datapoints that are actually true. From the below results we can see that precision for the \"Hate\" class is quite high. This could be because of the intersection of definitions of \"Hate\" and \"Offensive\" data/tweets. Thus we can see that there could be a lot of false positives associated with the \"Hate\" class because of which the the precision value is high. \n",
    "\n",
    "We can further notice that the recall value for \"Hate\" class is the comparitively less. Thus, the fraction of those predicted true over those actually true is low. So in a sense, we have a very picky classifier, which only picks hate tweets when there is a high probability - meaning a lot of hate tweets are also misclassified as for other classes. This is one huge shortcoming of the base model. In essence, our aim was to create a high-recall-low-precision classifier, so that no hate-tweet goes unnoticed. Should we create an automated moderator, any tweets misclassified as hate can definitely be repealed on dispute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "qvJofh4BICR3",
    "outputId": "2d40530b-aa5b-46c9-faae-62c73e4d5715"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.66      0.74       270\n",
      "           1       0.78      0.78      0.78       218\n",
      "           2       0.74      0.93      0.82       198\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       686\n",
      "   macro avg       0.78      0.79      0.78       686\n",
      "weighted avg       0.79      0.78      0.78       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report( y_test, y_preds )\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "colab_type": "code",
    "id": "t8zoTGI0cT6M",
    "outputId": "380b03bf-ee27-48e7-d5cb-5eae386d5c23"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAFHCAYAAAAySY5rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxoclR2OM8WHJ0RhjfPx/0geDMBsBJ9QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn\n",
    "confusion_matrix = confusion_matrix(y_test,y_preds)\n",
    "matrix_proportions = np.zeros((3,3))\n",
    "for i in range(0,3):\n",
    "    matrix_proportions[i,:] = confusion_matrix[i,:]/float(confusion_matrix[i,:].sum())\n",
    "names=['Hate','Offensive','Neither']\n",
    "confusion_df = pd.DataFrame(matrix_proportions, index=names,columns=names)\n",
    "plt.figure(figsize=(5,5))\n",
    "seaborn.heatmap(confusion_df,annot=True,annot_kws={\"size\": 12},cmap='gist_gray_r',cbar=False, square=True,fmt='.2f')\n",
    "plt.ylabel(r'True categories',fontsize=14)\n",
    "plt.xlabel(r'Predicted categories',fontsize=14)\n",
    "plt.tick_params(labelsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the confusion matrix for some interesting trends, we notice that :\n",
    "- 'Neither' has the highest accuracy and is rarely misclassified.\n",
    "- Quite understandably, most 'offensive' tweets that are misclassified are assigned to category 'hate'. This is argued in the base paper as well as one of the issues plaguing such classifier that categorize offensive tweets as hate speech.\n",
    "- Interestingly enough, misclassified hate tweets are more likely to be categorized as 'neither' than as 'offensive'. This is another problem that plagues classifiers that simply identify hate vs non-hate by a few key words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "id": "UE9a9t9qIb_z",
    "outputId": "fc2098f9-c6d3-4fd5-c25d-fdeb0b112d84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                B\n",
      "count  686.000000\n",
      "mean     1.049563\n",
      "std      0.823305\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      1.000000\n",
      "75%      2.000000\n",
      "max      2.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni16SCvd/XXdIpAJ4Jx8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "# load results file\n",
    "results = pd.DataFrame()\n",
    "results['B'] = y_preds\n",
    "# descriptive stats\n",
    "print(results.describe())\n",
    "# box and whisker plot\n",
    "# histogram\n",
    "results.hist()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "id": "lOoSYax2MDuV",
    "outputId": "c453f455-a17c-4e2c-ab81-835fdacc765f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                B\n",
      "count  686.000000\n",
      "mean     0.895044\n",
      "std      0.819866\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      1.000000\n",
      "75%      2.000000\n",
      "max      2.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7v8A7eNaHjhC9XwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "# load results file\n",
    "results = pd.DataFrame()\n",
    "results['B'] = y_test\n",
    "# descriptive stats\n",
    "print(results.describe())\n",
    "# box and whisker plot\n",
    "# histogram\n",
    "results.hist()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe, while the vast majority of our ground truth labels in test set are 'hate' and the other two have similar counts. This base classifier however tends to predict most observations as 'neutral'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges\n",
    "\n",
    "Given the task, most of the paper was simple to replicate and we were able to do it easily. The major questions that we had to ask at each step were fundamental and weren’t always answered in the paper.\n",
    "Two of the issues are as follows: \n",
    "The authors hadn’t handled data imbalance\n",
    "Testing was done only in sample\n",
    "Elaborating upon that:\n",
    "1. The original data has a major class imbalance. Even the paper states that only 1.5% of the tweets were labelled as “hate speech”. In all our replications, we’ve handled the imbalance by undersampling the data.\n",
    "2. The authors did cross-validation but while generating predictions, the data passed is only the training data. There is no explicit testing data.\n",
    "While not challenges, they were just things that we thought could be done differently. In our replication and extension, we have changed it.\n",
    "Another one of the challenges we faced was finding the right data. Majority of the data sources, especially the ones that pertained to twitter, the data was either highly imbalanced or no longer existed. For example, in https://github.com/ZeerakW/hatespeech , the twitter data we originally intended to replicate, on scraping twitter we found that most of the tweets that the author had labelled as hate were not available. We then moved to another dataset which had the text in it and didn’t require any scraping. It can be found here https://github.com/aitor-garcia-p/hate-speech-dataset\n",
    ".\n",
    "Given that we trained on a general hate speech data, we thought it would be interesting to see what it would be like to the performance of the model on another kind of hate.\n",
    "\n",
    "### Was everything clearly spelled out in the paper? \n",
    "The authors did clearly spell out the procedures and the paper was clear and lucid enough.However, we also had to make guesses at multiple places regarding what the authors were doing, especially regarding the data imbalance part, since they hadn’t mentioned dealing with it in the paper, we assumed the results given are on imbalanced data. \n",
    " \n",
    "### If your results differ from those in the paper, explain how and speculate as to why. \n",
    "Our results differ from the authors on multi-class classification, this is primarily because we handled data imbalance.  \n",
    "We obtained higher precision, accuracy than the paper. We suspect this is because the data was imbalanced in the original code, then on balancing it, since the dataset becomes much much smaller as compared to the original code, the accuracy increased.\n",
    "Our extensions have shown better performance on the data itself, in multiclass and binary classification, however on transfering the model to another dataset, we found our results dipped. This is probably because the methods and algorithms used are highly dependent on the words itself and not on the underlying meaning of the word.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions\n",
    "\n",
    "## Idea\n",
    "\n",
    "Offense is something that has a very specific individual target and the content is meant to hurt the person. Hate speech on the other hand is derogatory or is intended to either degrade the person.\n",
    "The authors differentiate between offense and hate speech, however for our extensions, we decided to just find the hate speech from the given texts. The motivation beyond lies in the fact that if implementing something similar in a real world scenario, it would be more useful to detect offensive content. We believe that it is better to misclassify something as hatespeech rather than it be missed altogether since the cost of missing hate speech is higher than the cost of having a human eye go through tweets classified as hate speech. Given the accuracy of the classifier, we thought it would be interesting to ultimately see how applicable the given algorithm is to a real world situation. We hence include the following steps to get to that: \n",
    "We decided to see this in three steps:\n",
    "\n",
    "    1.Do binary classification instead of multiclass classification\n",
    "    2.Extend the code to another dataset\n",
    "    3.Use a deep learning method based on word embeddings to reduce keyword based reliance.\n",
    "    \n",
    "We elaborate on them below:\n",
    "\n",
    "    1.Binary class replication We replicate the authors code on a binary class data, in this we merged the classes 1 and 2 (offensive and neutral). The code and the discussion of the results can be found in the “Binary_class_replication.\n",
    "    2. We extend the code to white supremacy hate speech dataset. The code is in “Train_test_twitter_extension” notebook. We find that although race based hate is a logical subset of the original general hate speech of our base data, the model doesnt generalize well because of its reliance on statistical features\n",
    "    3. Lastly, we use deep learning based methods to help decrease reliance on word based and statistical features. We used universal word embeddings[https://arxiv.org/abs/1803.11175] This helped us achieve better results on the training data and didn’t require as much time or feature engineering either. We believe working on these using a larger and more general dataset should help achieve a better accuracy over generalized hate and specific hate. The implementation is in the files: “Transfer_learning_binary_classification” and “Transfer_learning_multiclass”.\n",
    "\n",
    "In conclusion, given the small amount of data, high result metrics was very exciting. However, it also meant we should be cautious about it. One of the things was that we did to see how well the algorithm generalized was to test it on another dataset. Hence, we chose the below dataset: https://github.com/aitor-garcia-p/hate-speech-dataset and applied the author’s idea. We saw that it does not generalize well. This is probably because of the small size of the dataset and the different nature of the two datasets. While the original dataset is a general hatespeech data, we noticed it is skewed towards female hate speech (based on the exploratory data analysis results for most common word,s most common ngrams), our testing data for the second part was skewed towards supremacist hate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "\n",
    "We will summarize our conclusions as follows :\n",
    "- A high recall, low precision (relatively) model would be better than the high-precision low recall model that we have obtained here by replicating the base paper. Our aim is to not miss any hate speech since that is the most important category. Misclassified tweets can be contested with the moderators who will be human.\n",
    "- Models which associate hate vs non-hate by the presence of strong language do tend to have high accuracies, but also tend to misclassify a lot of terms that aren't necessarily hate speech merely by the presence of strong language.\n",
    "-Identifying the semantics via pos tagging, fkra, and other feature engineering methods can make our model more generalizable and less dependent on particular words.\n",
    "- And lastly a recurring issue with hate classifiers is that they tend to classify tweets as less offensive that the human encoders who annotated the dataset. Along with newer approaches, we will see if our extensions are able to overcome these challenges and provide better insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "multi-class Replicating MSD.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
