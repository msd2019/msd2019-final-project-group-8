{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning binary classification",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOTzp8O36CyQ",
        "colab_type": "text"
      },
      "source": [
        "# Getting Started\n",
        "\n",
        "This section sets up the environment for access to the Universal Sentence Encoder on TF Hub and provides examples of applying the encoder to words, sentences, and paragraphs.\n",
        "Tutorial followed:\n",
        "https://www.dlology.com/blog/keras-meets-universal-sentence-encoder-transfer-learning-for-text-data/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVjNK8shFKOC",
        "colab_type": "code",
        "outputId": "306d5bb0-c90e-4ce8-b8d5-c836f0a3bc14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "# Install the latest Tensorflow version.\n",
        "!pip3 install --quiet \"tensorflow>=1.7\"\n",
        "# Install TF-Hub.\n",
        "!pip3 install --quiet tensorflow-hub\n",
        "!pip3 install seaborn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.0.3)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.16.3)\n",
            "Requirement already satisfied: pandas>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (0.24.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.2->seaborn) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=1.4.3->seaborn) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63Pd3nJnTl-i",
        "colab_type": "text"
      },
      "source": [
        "More detailed information about installing Tensorflow can be found at [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSeY-MUQo2Ha",
        "colab_type": "code",
        "outputId": "bcf9a93f-7a54-4708-c0dd-abac5b7490e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "import keras.layers as layers\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "np.random.seed(10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0513 09:12:56.696139 140177703028608 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwty8Z6mAkdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8F4LNGFqOiq",
        "colab_type": "code",
        "outputId": "998e5508-7954-4047-c45c-9e2bf957cfa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "# Import the Universal Sentence Encoder's TF Hub module\n",
        "embed = hub.Module(module_url)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0513 09:12:58.129595 140177703028608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2cYc2WEkSGP",
        "colab_type": "code",
        "outputId": "72506da7-79ac-4b29-93f1-c56a05ccf3a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "embed_size = embed.get_output_info_dict()['default'].get_shape()[1].value\n",
        "embed_size"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp1eslsKYJ2P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "7463f332-3b59-4211-d5a4-5a097273dd89"
      },
      "source": [
        "df=pd.read_csv(\"labeled_data.csv\")\n",
        "\n",
        "df_train=df[['class', 'tweet']]\n",
        "# df.class = df.class.astype('category')\n",
        "df_train.loc[df_train['class'] == 2, 'class'] = 1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self.obj[item] = s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSu2r6IPZwz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.columns = [\"label\",\"text\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-FcmgZSbA3_",
        "colab_type": "code",
        "outputId": "ba6bf5ea-5b57-4ae4-d074-04109c9e5c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0      1  !!! RT @mayasolovely: As a woman you shouldn't...\n",
              "1      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
              "2      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
              "3      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
              "4      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT8rvJFWY3gD",
        "colab_type": "code",
        "outputId": "d5614dd7-67b6-4490-90ee-b600cfa502f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "df_train.label = df_train.label.astype('category')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:5096: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  self[name] = value\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HAtd4X5DayF",
        "colab_type": "code",
        "outputId": "095eb528-5fe4-4c49-f473-97157e4a29c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "category_counts = len(df_train.label.cat.categories)\n",
        "category_counts"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRD3fWgJjOrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def UniversalEmbedding(x):\n",
        "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3fllZkVjXKV",
        "colab_type": "code",
        "outputId": "5a1e0ee9-ddfc-49c4-896c-09b935ecf565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "input_text = layers.Input(shape=(1,), dtype=tf.string)\n",
        "embedding = layers.Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text)\n",
        "dense = layers.Dense(256, activation='relu')(embedding)\n",
        "pred = layers.Dense(category_counts, activation='softmax')(dense)\n",
        "model = Model(inputs=[input_text], outputs=pred)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0513 09:13:47.110457 140177703028608 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 131,842\n",
            "Trainable params: 131,842\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzj-Bp6IblkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hate=df_train[df_train.label==0]\n",
        "offensive=df_train[df_train.label==1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hNcx0FklZ6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hate=hate.sample(frac=1)\n",
        "offensive=offensive=offensive.sample(frac=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzleKqfmk3lq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_hate=hate[:min(len(hate), len(offensive))]\n",
        "new_off=offensive[:min(len(hate), len(offensive))]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVUVoIA4liPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_hate = new_hate.append(new_off)\n",
        "df_train=new_hate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ube1DvYEJ3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text = df_train['text'].tolist()\n",
        "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
        "\n",
        "train_label = np.asarray(pd.get_dummies(df_train.label), dtype = np.int8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX3s8yIVFWHI",
        "colab_type": "code",
        "outputId": "db0b4f87-12e0-4370-96e7-9fbeab535b4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_text.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2860, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOdbPegaUt-0",
        "colab_type": "code",
        "outputId": "3108ad8a-d692-4de0-fb0a-4c10b2b3ca5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_label.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2860, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqcRy_JWXe0u",
        "colab_type": "text"
      },
      "source": [
        "## Train Keras model and save weights\n",
        "This only train and save our Keras layers not the embed module' weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_stfC_7VFhS8",
        "colab_type": "code",
        "outputId": "22d6aa87-a3e5-4412-9213-14a0b446688e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        }
      },
      "source": [
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  history = model.fit(train_text, \n",
        "            train_label,\n",
        "            validation_split=0.2,\n",
        "            epochs=15,\n",
        "            batch_size=32)\n",
        "  model.save_weights('./model.h5')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2288 samples, validate on 572 samples\n",
            "Epoch 1/15\n",
            "  96/2288 [>.............................] - ETA: 23s - loss: 0.6691 - acc: 0.6146 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f7d1e7a1fd0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
            "    self._session._session, self._handle, status)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
            "    c_api.TF_GetCode(self.status.status))\n",
            "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2240/2288 [============================>.] - ETA: 0s - loss: 0.4946 - acc: 0.7433"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f7d1e7ba9e8>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1455, in __del__\n",
            "    self._session._session, self._handle, status)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n",
            "    c_api.TF_GetCode(self.status.status))\n",
            "tensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2288/2288 [==============================] - 4s 2ms/step - loss: 0.4926 - acc: 0.7448 - val_loss: 0.6258 - val_acc: 0.7255\n",
            "Epoch 2/15\n",
            "2288/2288 [==============================] - 2s 1ms/step - loss: 0.4047 - acc: 0.8129 - val_loss: 0.6695 - val_acc: 0.6766\n",
            "Epoch 3/15\n",
            "2288/2288 [==============================] - 2s 1ms/step - loss: 0.3891 - acc: 0.8239 - val_loss: 0.6470 - val_acc: 0.6923\n",
            "Epoch 4/15\n",
            "2288/2288 [==============================] - 2s 929us/step - loss: 0.3751 - acc: 0.8330 - val_loss: 0.6552 - val_acc: 0.6871\n",
            "Epoch 5/15\n",
            "2288/2288 [==============================] - 2s 926us/step - loss: 0.3623 - acc: 0.8405 - val_loss: 0.6202 - val_acc: 0.7185\n",
            "Epoch 6/15\n",
            "2288/2288 [==============================] - 2s 920us/step - loss: 0.3506 - acc: 0.8523 - val_loss: 0.5872 - val_acc: 0.7448\n",
            "Epoch 7/15\n",
            "2288/2288 [==============================] - 2s 945us/step - loss: 0.3364 - acc: 0.8549 - val_loss: 0.6078 - val_acc: 0.7378\n",
            "Epoch 8/15\n",
            "2288/2288 [==============================] - 2s 925us/step - loss: 0.3234 - acc: 0.8636 - val_loss: 0.7195 - val_acc: 0.6556\n",
            "Epoch 9/15\n",
            "2288/2288 [==============================] - 2s 925us/step - loss: 0.3048 - acc: 0.8820 - val_loss: 0.5392 - val_acc: 0.7675\n",
            "Epoch 10/15\n",
            "2288/2288 [==============================] - 2s 921us/step - loss: 0.2925 - acc: 0.8802 - val_loss: 0.7952 - val_acc: 0.6276\n",
            "Epoch 11/15\n",
            "2288/2288 [==============================] - 2s 923us/step - loss: 0.2746 - acc: 0.8929 - val_loss: 0.6273 - val_acc: 0.7028\n",
            "Epoch 12/15\n",
            "2288/2288 [==============================] - 2s 924us/step - loss: 0.2572 - acc: 0.8973 - val_loss: 0.6666 - val_acc: 0.7080\n",
            "Epoch 13/15\n",
            "2288/2288 [==============================] - 2s 932us/step - loss: 0.2420 - acc: 0.9047 - val_loss: 0.5735 - val_acc: 0.7465\n",
            "Epoch 14/15\n",
            "2288/2288 [==============================] - 2s 935us/step - loss: 0.2240 - acc: 0.9148 - val_loss: 0.6828 - val_acc: 0.6871\n",
            "Epoch 15/15\n",
            "2288/2288 [==============================] - 2s 923us/step - loss: 0.2111 - acc: 0.9248 - val_loss: 0.6458 - val_acc: 0.7168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQux6qLdXabG",
        "colab_type": "text"
      },
      "source": [
        "## Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSDxetlfUEiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new_text = list(s.comments)\n",
        "# new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
        "new_text=train_text\n",
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  model.load_weights('./model.h5')  \n",
        "  predicts = model.predict(new_text, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyDGVtigW57f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17368
        },
        "outputId": "78018068-075f-471d-990a-cfb822f90d45"
      },
      "source": [
        "categories = df_train.label.cat.categories.tolist()\n",
        "predict_logits = predicts.argmax(axis=1)\n",
        "predict_labels = [categories[logit] for logit in predict_logits]\n",
        "predict_labels"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASFZsfuYYjNX",
        "colab_type": "code",
        "outputId": "e0fd47f0-82a0-4009-e947-626434bd62df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1109
        }
      },
      "source": [
        "df_train.label"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10929    0\n",
              "731      0\n",
              "15654    0\n",
              "6487     0\n",
              "5362     0\n",
              "14198    0\n",
              "17757    0\n",
              "23325    0\n",
              "2704     0\n",
              "6348     0\n",
              "5513     0\n",
              "18038    0\n",
              "3006     0\n",
              "13413    0\n",
              "12254    0\n",
              "2521     0\n",
              "13722    0\n",
              "20266    0\n",
              "6454     0\n",
              "6683     0\n",
              "18676    0\n",
              "15269    0\n",
              "5580     0\n",
              "11681    0\n",
              "3902     0\n",
              "9066     0\n",
              "14591    0\n",
              "2472     0\n",
              "19351    0\n",
              "7029     0\n",
              "        ..\n",
              "6959     1\n",
              "23262    1\n",
              "4823     1\n",
              "16316    1\n",
              "8670     1\n",
              "19907    1\n",
              "19328    1\n",
              "6795     1\n",
              "17000    1\n",
              "606      1\n",
              "16066    1\n",
              "23951    1\n",
              "12734    1\n",
              "16608    1\n",
              "9583     1\n",
              "23466    1\n",
              "9601     1\n",
              "17598    1\n",
              "20461    1\n",
              "14899    1\n",
              "3030     1\n",
              "11003    1\n",
              "21150    1\n",
              "14061    1\n",
              "14112    1\n",
              "8654     1\n",
              "5911     1\n",
              "5391     1\n",
              "2787     1\n",
              "14194    1\n",
              "Name: label, Length: 2860, dtype: category\n",
              "Categories (2, int64): [0, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYcw696QcxLD",
        "colab_type": "code",
        "outputId": "46e8fcba-fcbe-4aed-e943-ad6b4e156eae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "tf.confusion_matrix(df_train.label, predict_labels)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/confusion_matrix.py:193: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0513 09:16:08.399286 140177703028608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/confusion_matrix.py:193: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'confusion_matrix/SparseTensorDenseAdd:0' shape=(2, 2) dtype=int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq2cVA7EXnE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(df_train.label, predict_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrtZXEATZYwk",
        "colab_type": "code",
        "outputId": "7ed99c9b-ab5f-41a2-cedb-0d81ba518c78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print(report)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.95      0.90      1430\n",
            "           1       0.94      0.84      0.89      1430\n",
            "\n",
            "   micro avg       0.89      0.89      0.89      2860\n",
            "   macro avg       0.90      0.89      0.89      2860\n",
            "weighted avg       0.90      0.89      0.89      2860\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1EMZjSyZZ1k",
        "colab_type": "code",
        "outputId": "0ac9fda3-c227-48f1-ed92-f4cf9131c60e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "import seaborn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(df_train.label, predict_labels)\n",
        "matrix_proportions = np.zeros((2,2))\n",
        "for i in range(0,2):\n",
        "    matrix_proportions[i,:] = confusion_matrix[i,:]/float(confusion_matrix[i,:].sum())\n",
        "names=['Hate','Offensive']\n",
        "confusion_df = pd.DataFrame(matrix_proportions, index=names,columns=names)\n",
        "plt.figure(figsize=(5,5))\n",
        "seaborn.heatmap(confusion_df,annot=True,annot_kws={\"size\": 12},cmap='gist_gray_r',cbar=False, square=True,fmt='.2f')\n",
        "plt.ylabel(r'True categories',fontsize=14)\n",
        "plt.xlabel(r'Predicted categories',fontsize=14)\n",
        "plt.tick_params(labelsize=12)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAFHCAYAAAAySY5rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOjn3kUJepDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}